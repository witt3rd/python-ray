{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray: Cloud Native Distributed Computing Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Core Links\n",
    "- [ray.io](https://www.ray.io/)\n",
    "- [docs.ray.io](https://docs.ray.io/)\n",
    "- [github/ray-project](github.com/ray-project/ray)\n",
    "\n",
    "##### Papers and Posts\n",
    "- [Cloud Programming Simplified: A Berkeley View on Serverless Computing](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-3.pdf)\n",
    "- [Modern Parallel and Distributed Python: A Quick Tutorial on Ray](https://towardsdatascience.com/modern-parallel-and-distributed-python-a-quick-tutorial-on-ray-99f8d70369b8)\n",
    "- [Combine the development experience of a laptop with the scale of the cloud](https://gradientflow.com/combine-the-development-experience-of-a-laptop-with-the-scale-of-the-cloud/)\n",
    "\n",
    "##### Videos\n",
    "- [Ray Core Tutorial](https://youtu.be/_KOlq2C-568) ([source code](https://github.com/derwenai/ray_tutorial))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray is:\n",
    "\n",
    "1) A simple and flexible framework for distributed cloud computing\n",
    "    a) Simple: simple annotation to make functions & classes distribute.\n",
    "    b) Flexible: create new distributed function calls & instances.  No batching required.\n",
    "2) A cloud-provider independent compute launcher/autoscaler\n",
    "3) An ecosystem of distributed computation libraries build with #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does it \"fit\" with ML?\n",
    "\n",
    "[3rd generation ML architecture](https://www.anyscale.com/blog/the-third-generation-of-production-ml-architectures): tackling the problem of production ML architecure by making it programmable.\n",
    "\n",
    "Moves the focus to libraries instead of worried about distributed computation and underlying clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simpler way to build 1st/2nd generation ML pipelines\n",
    "\n",
    "- Flexibility of a programming language to define pipelines\n",
    "- More easily allows for shared components (e.g., feature transformation during training vs real-time)\n",
    "- \"Out of the box\" support for distributed ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray Core\n",
    "\n",
    "A *pattern language* for distibuted systems as a library in Python, Java, and C++.\n",
    "\n",
    "- task-parallel - stateless, data independence\n",
    "- remote objects - key/value store\n",
    "- actor pattern - messages among classes, managing state\n",
    "- parallel iterators - lazy, infinite sequences\n",
    "- multiprocessing.Pool - drop-in replacement\n",
    "- joblib - e.g., _scikit-learn_ back-end\n",
    "- Dask, Modin, Mars, etc.\n",
    "\n",
    "Mix and match as needed, without tight coupling to framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ray Head and Worker Nodes](images/ray_head_worker_nodes.jpg)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b8993322de9988bf4d1f2a5a315dbb9729831e2e9420b872ad242b038970356"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('ray-d0a2q5pH': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
